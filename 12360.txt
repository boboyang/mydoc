简单说，在线服务scalability有两种方式，scale-up和scale-out。Scale-up追求单机性能，如高级硬件、异步架构等，而scale-out则用加机器的方法。Scale-out也是最简单的方法，在规模不是非常大时很好用，也很容易解决问题，普通工程师就足以胜任。有很多现成的方法或模块可以使用。
但为什么很多时候系统还是崩溃呢？罪魁祸首就是请求的尖峰，10倍于平常的压力是很正常的。普通模型到达性能瓶颈后，开始堆积请求（可能在web server，也可能在请求队列，不过通常不会在CDN），吞吐急剧下降，延迟急剧上升，而随着堆积请求越多，情况越糟，引起雪崩效应。而这样的压力通常不会持续很久，如果性能不急剧下降的话，一段时间后其实也就能把请求都响应了。

为10倍压力而准备机器是不合适的，我们需要有办法能扛住瞬间压力。这时候架构设计主要考虑的问题，也就是我上个weibo所说的，如何保证极限情况下的稳定吞吐。
有很多种办法，分级队列、请求调度、延迟截断、主动拒绝等等，这些都有助于帮系统度过艰难时刻。具体的做法，就不在这里讨论了。

如何用软件架构的方法来实现scale-up就很困难，做得好与不好可能性能差异能达几倍到一个量级。但对于普通公司来说，直接scale-out是最合适的，规模不大时多一些机器也不会对成本产生太大影响。

对于一个理想的在线服务系统，应该包括几方面的能力。1) 单机高性能，也就是所谓的c10k能力。2) 良好的scalability。简单来说，就是加机器可以提升系统性能。3) 稳定输出，特别在极限情况下。4) 良好的自管理自运维能力，在故障、升级或扩容时尽量减少人工介入。
a) 可以先不考虑1，因为要提高单机性能难度很大，而效果却并不明显，通过加点机器即可取得同样效果。当然，作为一个old-fashioned engineer，我个人很喜欢做这样的事情。百度的快照库是我到百度后做的第一个系统，单机性能比旧系统提升了10倍以上。

b) 在业务不太复杂的情况下，加机器是最容易提升scalability的方法。我不了解具体的火车票业务模型，不太好讨论，但通常只要能把锁和正常的业务逻辑decouple，问题就不大了。谈到锁，多说两句。用它来保证的同步互斥，是并行系统中最基本的问题。有很多种做法，难度迥异。比如一些lock-free patterns，如果工程师的志向不在于此，不建议尝试。在实际中，按照我的review经验，只要能分解掉那把全局大锁，效果就很好了。

c) 最重要的是sustained throughput。在峰值压力情况下，平滑过渡，可以有效避免雪崩效应，大幅提升用户体验。我提了一些做法，很多朋友说这在通信系统中也是常用的。有兴趣的朋友也可以去研究一下queueing theory，看看latency和throughput是怎样的关系。

d) 在小规模时可以先不考虑自管理自运维能力。随着机群的扩展，故障处理、扩容减容以及服务调度等等逐渐成为最头疼的问题，而这正是分布式系统所要解决的最难的问题。对于大互联网公司来说，应该深有体会。


在系统设计时，有一些永恒的矛盾需要做出折中考虑，例如延迟与吞吐、公平与效率。
在桌面环境中，我们选择了低延迟和公平，
而在数据中心环境中，我们选择了高吞吐（或稳定的极限吞吐）和高效率。在具体实现方案上，也带来了不同的选择，比如同步与异步模型、线程与事件驱动、线程池与队列等。

在系统的每一层中，都可能存在一些重复的功能。以存储为例，一次写入需要经历从libc的文件流（FILE stream），到文件系统的缓冲区，再到驱动器中的缓冲区，最后到磁盘上的缓存这样的长调用流程才能完成持久化（persistency）。这个流程从其中的每一层单独来看都是合理的，但从整个系统的角度看来，存在着性能浪费。另外，由于分层带来的透明性使得数据持久化不得不通过额外的fsync操作才得以保证，从而使系统的可靠性保证机制变得更复杂。

以SSD为例，现在的SSD在设计时通常假设由文件系统来使用。SSD的逻辑其实可以做得非常简单，直接对上层暴露内部的状态（如通路、物理块），从而提高性能、降低成本。更重要的是，这将有效提高交付速度——这对于缓解服务器、网络、IDC等硬件系统的长实施周期和业务快速增长的规模需求之间的矛盾至关重要。

一个中等规模的数据中心通常包含数万服务器，在这样的规模下，硬件故障成为家常便饭。一般，我们通过冗余复制或者重复处理来解决硬件故障问题。在习惯了硬件故障之后，我们对软件Bug的态度也会发生变化。软件Bug中有一种偶发性Bug【注：也被称为heisenbug，意指海森堡测不准原理】最难发现也最难调试，消除这些Bug需要付出巨大的代价。但考虑到这种Bug的出现概率堪比硬件故障，我们其实可以采用同样的方式来对待。

现在的系统设计原则是在桌面环境中历时30余年发展起来的，但到了今天已经完全不适应数据中心环境，我们需要重新思考并总结出适用的设计原则，这体现在如下三个方面。

从单用户多任务到多用户单任务的环境变化，导致我们在系统设计时重新审视对延迟与吞吐、公平与效率的折中考虑。
自行开发全套系统成为可能，透明性不再是美德，架构由层次化向竖井式演进，系统由需求驱动而定制。
由于规模与复杂度增大，我们不再追求零缺陷，而是与故障和Bug共舞。同时数据也成为系统的一部分，这些都使得以前的确定性系统变得不确定，评价指标也由正确性（correctness）向精确度（precision）转变。




